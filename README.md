# TP NÂ° 3 : Analyse OLAP sur des Bases de DonnÃ©es Publiques

**Auteurs:** Ouled Meriem Farouk; Mezouari Abdel El Kader  
**Institution:** University Sid M2  
**Cours:** Analyse OLAP et Bases de DonnÃ©es Multidimensionnelles  
**Date:** 2026-01-07

---

## ğŸ“š Rapport AcadÃ©mique Complet

### Table des MatiÃ¨res

1. [Introduction](#1-introduction)
2. [Partie 1: Recherche et PrÃ©paration des DonnÃ©es](#2-partie-1-recherche-et-prÃ©paration-des-donnÃ©es)
3. [Partie 2: RequÃªtes OLAP](#3-partie-2-requÃªtes-olap)
4. [Partie 3: Visualisation des RÃ©sultats](#4-partie-3-visualisation-des-rÃ©sultats)
5. [Partie 4: Analyse et InterprÃ©tation](#5-partie-4-analyse-et-interprÃ©tation)
6. [Conclusion](#6-conclusion)
7. [Annexes](#7-annexes)

---

## 1. Introduction

### 1.1 Objectif du Projet

Ce travail pratique dÃ©montre une chaÃ®ne de valeur analytique endâ€‘toâ€‘end sur un dataset public de ventes: **modÃ©lisation dimensionnelle (schÃ©ma en Ã©toile)**, **ETL Python â†’ PostgreSQL**, **requÃªtes SQLâ€‘OLAP avancÃ©es**, et **visualisations**.

### 1.2 Technologies UtilisÃ©es

- Base: PostgreSQL
- Langages: SQL, Python 3.8+
- BibliothÃ¨ques: pandas, SQLAlchemy, matplotlib, seaborn
- Outils: Jupyter Notebooks (VS Code)

### 1.3 MÃ©thodologie

1. ETL depuis CSV vers PostgreSQL
2. ModÃ©lisation: 4 dimensions + 1 table de faits
3. RequÃªtes OLAP: agrÃ©gats, ROLLUP, CUBE, GROUPING SETS, RANK/DENSE_RANK, PIVOT, fenÃªtres
4. Visualisations: dashboard, comparaison RANK, heatmap

### 1.4 Dataset Choisi

- **Source:** Kaggle - Sales Forecasting Dataset (Superstore)
- **Fichier Local:** `data/row_data.csv`
- **VolumÃ©trie:** 9 994 transactions
- **Grain analytique:** 1 ligne = 1 produit dans une commande

**Dictionnaire des DonnÃ©es (`row_data.csv`):**

| Champ Original | Type    | Description                                             |
| -------------- | ------- | ------------------------------------------------------- |
| Order Date     | Date    | Date de la transaction                                  |
| Order ID       | String  | Identifiant unique de la commande                       |
| Customer ID    | String  | Identifiant unique du client                            |
| Customer Name  | String  | Nom complet du client                                   |
| Segment        | String  | Segment client (Consumer, Corporate, Home Office)       |
| Country        | String  | Pays (majoritairement United States)                    |
| City           | String  | Ville de livraison                                      |
| State          | String  | Ã‰tat de livraison                                       |
| Postal Code    | Integer | Code postal                                             |
| Region         | String  | RÃ©gion commerciale (West, East, Central, South)         |
| Product ID     | String  | Identifiant unique du produit                           |
| Category       | String  | CatÃ©gorie de produit (Furniture, Office Supplies, Tech) |
| Sub-Category   | String  | Sous-catÃ©gorie (Chairs, Phones, etc.)                   |
| Product Name   | String  | Nom complet du produit                                  |
| Sales          | Decimal | Montant de la vente                                     |
| Quantity       | Integer | QuantitÃ© vendue                                         |
| Discount       | Decimal | Remise appliquÃ©e (si disponible)                        |
| Profit         | Decimal | Profit rÃ©alisÃ© (si disponible)                          |

---

## 2. Partie 1: Recherche et PrÃ©paration des DonnÃ©es

Notebook principal: `notebooks/01_etl_postgres_star_schema.ipynb`

### 2.1 ModÃ©lisation Dimensionnelle (Star Schema)

Nous avons transformÃ© le fichier plat (`row_data.csv`) en un modÃ¨le en Ã©toile optimisÃ© pour l'analyse OLAP.

#### SchÃ©ma Conceptuel

- **RÃ©fÃ©rentiel Central (Fait):** `fact_sales` contient les mesures quantitatives (`sales`, `quantity`).
- **Dimensions:** Tables descriptives dÃ©normalisÃ©es pour l'axe d'analyse.

**Avantages du modÃ¨le en Ã©toile:**

- RequÃªtes plus simples (moins de JOINS complexes)
- Performance accrue pour les agrÃ©gations
- ExtensibilitÃ© facile

![Star Schema Diagram](./images/star_schema.png)
_Figure 1 â€” SchÃ©ma en Ã©toile du Data Warehouse_

### 2.2 Configuration PostgreSQL

Connexion via SQLAlchemy: `postgresql://postgres:aa@localhost:5432/olap`

### 2.3 Processus ETL (Extract-Transform-Load)

Le pipeline ETL est implÃ©mentÃ© en Python et SQL :

1. **Extraction (Extract):**

   - Chargement du CSV dans un DataFrame Pandas.
   - Nettoyage des noms de colonnes (snake_case).
   - Conversion des types (Dates, codes postaux).

2. **Transformation (Transform):**

   - **Dimension Time:** GÃ©nÃ©ration d'une dimension temporelle riche (AnnÃ©e, Trimestre, Mois, Jour) Ã  partir des dates uniques.
   - **Dimension Customer:** Extraction unique des couples `(customer_id, customer_name, segment)`.
   - **Dimension Product:** Extraction unique des produits `(product_id, category, sub_category, product_name)`. DÃ©duplication stricte sur `product_id`.
   - **Dimension Geography:** Extraction unique des lieux `(country, city, state, postal_code, region)`.

3. **Chargement (Load):**
   - Insertion des donnÃ©es dimensionnelles dans PostgreSQL (gÃ©nÃ©ration automatique des clÃ©s primaires `SERIAL`).
   - CrÃ©ation de la table de faits `fact_sales` en joignant les donnÃ©es brutes avec les clÃ©s primaires des dimensions nouvellement crÃ©Ã©es.

![ETL Process Overview](./images/etl_overview.png)
_Figure 2 â€” Processus ETL de bout en bout_

> **Explication Figure 2:** Ce diagramme montre le flux de donnÃ©es en 3 Ã©tapes. Ã€ gauche, la donnÃ©e brute (CSV). Au centre, la transformation Python qui Ã©clate les donnÃ©es en entitÃ©s logiques (Temps, Client, Produit). Ã€ droite, le chargement dans la base de donnÃ©es PostgreSQL oÃ¹ les relations sont reconstruites via des clÃ©s Ã©trangÃ¨res, formant le schÃ©ma final.

### 2.4 Indexation et VÃ©rifications

Pour optimiser les performances des requÃªtes OLAP:

- **ClÃ©s Ã‰trangÃ¨res:** Indexation de `time_key`, `geo_key`, `customer_key`, `product_key` dans `fact_sales`.
- **IntÃ©gritÃ©:** VÃ©rification qu'aucune vente n'est orpheline (toutes les clÃ©s Ã©trangÃ¨res sont valides).

![Database Verification](./images/db_verification.png)
_Figure 3 â€” VÃ©rifications de structure et dâ€™intÃ©gritÃ©_

> **Explication Figure 3:** Ce tableau rÃ©sumÃ© montre, aprÃ¨s l'ETL, le nombre de lignes insÃ©rÃ©es dans chaque table. On observe que `fact_sales` contient environ 10,000 lignes (la totalitÃ© des commandes), tandis que les dimensions sont dÃ©doublonnÃ©es (ex: seulement 1850 produits uniques). Cela confirme que la normalisation en Ã©toile a rÃ©ussi Ã  rÃ©duire la redondance des donnÃ©es descriptives.

---

## 3. Partie 2: RequÃªtes OLAP

Notebook: `notebooks/03_olap_queries.ipynb`

Cette partie dÃ©montre l'utilisation de fonctions SQL avancÃ©es pour extraire des insights multidimensionnels.

### 3.1 Task 5 â€” AgrÃ©gats de base (SUM, AVG, COUNT, MIN, MAX)

**Objectif:** Obtenir une vue d'ensemble des mÃ©triques clÃ©s.

- **RequÃªtes:** Calcul des ventes totales, moyennes, quantitÃ©s et nombre de transactions. ExÃ©cution de ces agrÃ©gats par axes (catÃ©gorie, rÃ©gion, temps).
- **RÃ©sultat observÃ©:**
  - Ventes totales globales: ~2.3M$
  - CatÃ©gorie la plus performante: "Technology"
  - RÃ©gion la plus forte: "West"

![Task 5 Aggregates](./images/task5_aggregates.png)
_Figure 4 â€” RÃ©sultats des agrÃ©gats_

> **Explication Figure 4:** Cette capture montre le rÃ©sultat d'une requÃªte `GROUP BY category`. On y voit pour chaque catÃ©gorie (Furniture, Office Supplies, Technology) la somme totale des ventes. Cela permet d'identifier quelle gamme de produits gÃ©nÃ¨re le plus de chiffre d'affaires. C'est le niveau d'analyse le plus basique mais essentiel.

### 3.2 Task 6 â€” GROUP BY ROLLUP

**Objectif:** Obtenir des sous-totaux hiÃ©rarchiques automatiques.

- **Concept:** `ROLLUP(A, B)` gÃ©nÃ¨re: `(A, B)`, `(A, NULL)` [sous-total A], `(NULL, NULL)` [grand total].
- **Application:** Analyse des ventes par `Category` â†’ `Sub-Category`.
- **RÃ©sultat:** Permet de voir en une seule table les ventes de "Phones", le total "Technology", et le total gÃ©nÃ©ral de l'entreprise.

![Task 6 ROLLUP](./images/task6_rollup.png)
_Figure 5 â€” ROLLUP catÃ©gorie/sousâ€‘catÃ©gorie_

> **Explication Figure 5:** Ici, on observe des lignes oÃ¹ la colonne `sub_category` est `NULL` (reprÃ©sentant le total de la catÃ©gorie) et une ligne tout en bas oÃ¹ `category` et `sub_category` sont `NULL` (le grand total). Cette structure hiÃ©rarchique est typique des rapports financiers oÃ¹ l'on veut voir le dÃ©tail et le rÃ©sumÃ© simultanÃ©ment.

### 3.3 Task 7 â€” GROUP BY CUBE

**Objectif:** Analyser toutes les combinaisons possibles de dimensions (Cross-Tabulation).

- **Concept:** `CUBE(A, B)` gÃ©nÃ¨re: `(A, B)`, `(A, NULL)`, `(NULL, B)`, `(NULL, NULL)`.
- **Application:** Analyse croisÃ©e `Region` Ã— `Segment`.
- **RÃ©sultat:** RÃ©vÃ¨le la performance de chaque segment dans chaque rÃ©gion, mais aussi les totaux par rÃ©gion (tous segments) et par segment (toutes rÃ©gions).

![Task 7 CUBE](./images/task7_cube.png)
_Figure 6 â€” CUBE rÃ©gion/segment_

> **Explication Figure 6:** Le rÃ©sultat du CUBE est plus volumineux que le ROLLUP. Il montre non seulement les totaux par rÃ©gion mais aussi les totaux par segment (ex: total des ventes "Consumer" pour tout le pays), ce que le ROLLUP hiÃ©rarchique ne ferait pas. C'est utile pour explorer les donnÃ©es sans "chemin" prÃ©dÃ©fini.

### 3.4 Task 8 â€” GROUPING SETS

**Objectif:** Cibler prÃ©cisÃ©ment les niveaux d'agrÃ©gation d'intÃ©rÃªt (Optimisation).

- **Concept:** SpÃ©cifier explicitement les groupes souhaitÃ©s (ex: `(Region)`, `(Category)`), Ã©vitant le calcul de combinaisons inutiles.
- **Application:** Comparaison directe des ventes par RÃ©gion vs ventes par CatÃ©gorie dans un seul rapport unifiÃ©.

![Task 8 Grouping Sets](./images/task8_grouping_sets.png)
_Figure 7 â€” GROUPING SETS_

> **Explication Figure 7:** Cette figure montre une liste personnalisÃ©e de rÃ©sultats. Contrairement Ã  CUBE qui gÃ©nÃ¨re tout, ici nous avons demandÃ© spÃ©cifiquement deux vues : "Performance par RÃ©gion" et "Performance par CatÃ©gorie", affichÃ©es l'une Ã  la suite de l'autre. C'est trÃ¨s efficace pour gÃ©nÃ©rer des Ã©lÃ©ments de dashboard spÃ©cifiques en une seule requÃªte SQL.

### 3.5 Task 9 â€” RANK et DENSE_RANK

**Objectif:** Ã‰tablir des classements (Ranking).

- **Concept:**
  - `RANK()`: Laisse des "trous" aprÃ¨s Ã©galitÃ© (1, 2, 2, 4).
  - `DENSE_RANK()`: Pas de trous (1, 2, 2, 3).
- **Application:** Identification des "Top Products" et "Top Customers" au global et par rÃ©gion (`PARTITION BY`).
- **RÃ©sultat:** Identification rapide des produits "Stars" (ex: Canon imageCLASS Copier).

![Task 9 Ranking](./images/task9_ranking.png)
_Figure 8 â€” RANK vs DENSE_RANK (Resultats SQL)_

> **Explication Figure 8:** Ce tableau montre les 20 meilleurs produits classÃ©s par chiffre d'affaires. La colonne `sales_rank` indique leur position. Si deux produits avaient exactement le mÃªme montant de ventes, ils auraient le mÃªme rang. C'est l'outil standard pour dÃ©finir les "Top N" performeurs.

### 3.6 Task 10 â€” PIVOT

**Objectif:** Transformer les donnÃ©es ligne en colonnes pour des rapports lisibles.

- **MÃ©thode:** PostgreSQL utilise `SUM(CASE WHEN ...)` pour simuler un pivot.
- **Application:**
  - Tableau Ventes par CatÃ©gorie (Lignes) vs AnnÃ©es (Colonnes).
  - Tableau Ventes par RÃ©gion (Lignes) vs Segment (Colonnes).
- **RÃ©sultat:** Tableaux compacts facilitant la comparaison temporelle ou catÃ©gorielle.

![Task 10 Pivot](./images/task10_pivot.png)
_Figure 9 â€” Tableaux croisÃ©s de ventes_

> **Explication Figure 9:** Ce rÃ©sultat ressemble Ã  un tableau Excel croisÃ© dynamique. Les annÃ©es (2014, 2015, 2016, 2017) sont devenues des colonnes. Cela permet de lire horizontalement l'Ã©volution des ventes d'une catÃ©gorie (ex: Furniture) annÃ©e aprÃ¨s annÃ©e, ce qui est beaucoup plus intuitif qu'une longue liste verticale.

### 3.7 Task 11 â€” Fonctions de FenÃªtre

**Objectif:** Analyser des tendances sans rÃ©duire le nombre de lignes (Analytics).

- **Application:**
  - **Cumulatives (Running Total):** Ventes cumulÃ©es jour par jour.
  - **Moyennes Mobiles (Moving Avg):** Lissage des ventes sur 7 jours ou 3 mois.
  - **LAG/LEAD:** Calcul de la croissance Mois-sur-Mois (MoM Growth).

![Task 11 Windows](./images/task11_windows.png)
_Figure 10 â€” Cumulatives et moyennes mobiles_

> **Explication Figure 10:** On voit ici pour chaque date, non seulement les ventes du jour, mais aussi une colonne `cumulative_sales` qui augmente continuellement (somme depuis le dÃ©but) et une `moving_avg` qui lisse les pics et creux journaliers. Cela permet de visualiser la tendance de fond et la progression totale du chiffre d'affaires.

---

## 4. Partie 3: Visualisation des RÃ©sultats

Notebook: `notebooks/04_visualizations.ipynb`

L'analyse visuelle permet de communiquer les insights plus efficacement.

### 4.1 Task 12 â€” Dashboard: Ventes par CatÃ©gorie et AnnÃ©e

**Description:** Tableau de bord synthÃ©tique composÃ© de 4 graphiques:

1. **Bar Chart Horizontal:** Classement des catÃ©gories par volume.
2. **Line Chart:** Ã‰volution temporelle (trend) montrant la saisonnalitÃ©.
3. **Grouped Bar Chart:** Comparaison directe annÃ©e par annÃ©e (YoY).
4. **Pie Chart:** Part de marchÃ© de chaque catÃ©gorie.

**Insight:** La catÃ©gorie "Furniture" montre une volatilitÃ© saisonniÃ¨re marquÃ©e par rapport Ã  "Office Supplies".

![Dashboard Sales by Category and Year](./images/task12_dashboard.png)
_Figure 11 â€” Dashboard complet_

> **Explication Figure 11:** Ce tableau de bord offre une vue Ã  360Â°.
>
> - En haut Ã  gauche (Barres), on voit instantanÃ©ment que "Technology" rapporte le plus.
> - En haut Ã  droite (Lignes), on suit l'Ã©volution mois par mois; les pics correspondent souvent aux fÃªtes de fin d'annÃ©e.
> - En bas Ã  gauche (Barres groupÃ©es), on compare la croissance sur 4 ans; on note une augmentation constante chaque annÃ©e.
> - En bas Ã  droite (Pie chart), on voit que la rÃ©partition est assez Ã©quilibrÃ©e (~30% par catÃ©gorie), ce qui indique un business sain et diversifiÃ©.

### 4.2 Task 13 â€” Comparaison Graphique RANK vs DENSE_RANK

**Description:** Visualisation comparative cÃ´te-Ã -cÃ´te.

- Montre concrÃ¨tement comment les rangs divergent aprÃ¨s une Ã©galitÃ© de ventes.
- Utile pour choisir la bonne fonction selon le besoin mÃ©tier (compÃ©tition vs classification).

![RANK vs DENSE_RANK](./images/task13_rank_vs_dense.png)
_Figure 12 â€” Comparaison visuelle des fonctions de ranking_

> **Explication Figure 12:** Ce graphique compare deux mÃ©thodes de classement.
>
> - Ã€ gauche (RANK), si le 2Ã¨me et 3Ã¨me sont ex-aequo, le suivant sera classÃ© 4Ã¨me. C'est utile pour les compÃ©titions (il n'y a que 3 places sur le podium).
> - Ã€ droite (DENSE_RANK), le suivant serait classÃ© 3Ã¨me. C'est utile pour grouper des produits par niveau de performance (ex: "Tier 1", "Tier 2").
>   On voit visuellement si des sauts de numÃ©rotation se produisent dans les donnÃ©es.

### 4.3 Task 14 â€” Heatmap: RÃ©gion Ã— Trimestre

**Description:** Carte thermique (Matrice de couleurs).

- **Axe X:** AnnÃ©e-Trimestre (Q1-Q4).
- **Axe Y:** RÃ©gion (West, East, etc.).
- **Couleur:** IntensitÃ© des ventes (Rouge = Fort, Jaune = Faible).

**Insight:** Le 4Ã¨me trimestre (Q4) est systÃ©matiquement le plus fort dans toutes les rÃ©gions, indiquant une forte saisonnalitÃ© de fin d'annÃ©e.

![Heatmap Region Ã— Quarter](./images/task14_heatmap.png)
_Figure 13 â€” Heatmap des ventes_

> **Explication Figure 13:** La Heatmap permet de repÃ©rer les modÃ¨les en un coup d'Å“il.
>
> - Les **zones rouges** (ventes fortes) se concentrent sur la colonne "Q4" (Trimestre 4), confirmant que la fin d'annÃ©e est cruciale.
> - La ligne "West" est globalement plus foncÃ©e que "South", confirmant visuellement que la rÃ©gion Ouest est la plus performante.
>   C'est un excellent outil pour dÃ©cider oÃ¹ et quand allouer les budgets marketing.

---

## 5. Partie 4: Analyse et InterprÃ©tation

### 5.1 SynthÃ¨se du Dataset

- PÃ©riode: 2014â€“2017
- Transactions: ~10k lignes
- Dimensions: Time (dates, annÃ©es, trimestres, mois), Customer (segments), Geography (4 rÃ©gions US), Product (3 catÃ©gories)

### 5.2 Tendances et Insights

- CatÃ©gories: Technology souvent dominante en chiffre dâ€™affaires; Office Supplies volumÃ©trique
- RÃ©gions: West/East plus fortes; Central/South Ã  potentiel
- Saisonniers: Q4 > Q1 (pics fin dâ€™annÃ©e)
- Ranking: quelques produits highâ€‘ticket expliquent une large part des ventes
- Pareto: ~20% des produits â‰ˆ ~70â€“80% des ventes (Ã  confirmer selon exÃ©cution locale)

### 5.3 Limites

- Absence de coÃ»t/profit â†’ analyse en revenus uniquement
- DonnÃ©es centrÃ©es US â†’ pas de vision internationale
- PÃ©riode limitÃ©e (2014â€“2017) â†’ actualitÃ© Ã  vÃ©rifier
- Pas de promotions/canaux â†’ dimensions business incomplÃ¨tes

### 5.4 Pistes dâ€™AmÃ©lioration

- Ajouter mesures `discount`, `profit`, dÃ©lais, retours
- Dimension Channel/Promotion; SCD Type 2 pour lâ€™historique
- Vues matÃ©rialisÃ©es/partitionnement pour accÃ©lÃ©rer
- PrÃ©diction (Prophet/ARIMA), segmentation (Kâ€‘means), RFM/CLV

---

## 6. Conclusion

Objectifs du TP atteints:

1. ETL reproductible vers PostgreSQL
2. SchÃ©ma en Ã©toile propre et indexÃ©
3. RequÃªtes OLAP complÃ¨tes (Tasks 5â€“11)
4. Visualisations explicatives (Tasks 12â€“14)  
   â†’ Base solide pour BI/Data Warehousing et analyses avancÃ©es.

---

## 7. Annexes

### 7.1 Structure du Projet

```
tp_olap/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ row_data.csv
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_etl_postgres_star_schema.ipynb
â”‚   â”œâ”€â”€ 02_database_info.ipynb
â”‚   â”œâ”€â”€ 03_olap_queries.ipynb
â”‚   â””â”€â”€ 04_visualizations.ipynb
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ schema.sql
â”œâ”€â”€ visualization/
â”œâ”€â”€ images/               # â† Placeholders pour les captures
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

### 7.2 ReproductibilitÃ©

PrÃ©â€‘requis: PostgreSQL local (`olap`), Python 3.8+, `pip install -r requirements.txt`

ExÃ©cution (ordre):

1. `notebooks/01_etl_postgres_star_schema.ipynb`
2. `notebooks/02_database_info.ipynb` (documentation DB)
3. `notebooks/03_olap_queries.ipynb`
4. `notebooks/04_visualizations.ipynb`

### 7.3 Placeholders Images

DÃ©posez les captures au chemin `images/` en gardant les noms utilisÃ©s ciâ€‘dessus (ex.: `task12_dashboard.png`).

### 7.4 RÃ©fÃ©rences

- PostgreSQL Docs (ROLLUP, CUBE, GROUPING SETS, Window Functions)
- Kimball & Ross â€” The Data Warehouse Toolkit (3e)
- Pandas / SQLAlchemy / Matplotlib / Seaborn docs
- Dataset: Kaggle (Superstoreâ€‘like retail)
